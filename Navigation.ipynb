{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "By trying out this notebook you will learn how to use [ the Unity ML-Agents environment](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Learning-Environment-Examples.md) and especially the [Banana Collector](https://youtu.be/heVMs3t9qSk) environment for a project of Udacity's [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893)\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Execute the next cells below to install a few packages like Python and UnityEnvironment. Double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 2.0.9 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also start the environment! Before running the code cell below, change the file_name parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- Mac: \"path/to/Banana.app\"\n",
    "- Windows (x86): \"path/to/Banana_Windows_x86/Banana.exe\"\n",
    "- Windows (x86_64): \"path/to/Banana_Windows_x86_64/Banana.exe\"\n",
    "- Linux (x86): \"path/to/Banana_Linux/Banana.x86\"\n",
    "- Linux (x86_64): \"path/to/Banana_Linux/Banana.x86_64\"\n",
    "- Linux (x86, headless): \"path/to/Banana_Linux_NoVis/Banana.x86\"\n",
    "- Linux (x86_64, headless): \"path/to/Banana_Linux_NoVis/Banana.x86_64\"\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded Banana.app. If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "\n",
    "- env = UnityEnvironment(file_name=\"Banana.app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# please do not modify the line below\n",
    "env = UnityEnvironment(file_name=\"/data/Banana_Linux_NoVis/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Using this Unity Banana environment, the objective of the project is to design an agent to navigate (and collect bananas!) in a large, square world. A reward of +1 is provided for collecting a yellow banana, and a reward of -1 is provided for collecting a blue banana. Thus, the goal of the agent is to collect as many yellow bananas as possible while avoiding blue bananas. The agent’s observation space is 37 dimensional and the agent’s action space is 4 dimensional (forward, backward, turn left, and turn right). The task is episodic, and in order to solve the environment, the agent must get an average score of +13 over 100 consecutive episodes.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [ 1.          0.          0.          0.          0.84408134  0.          0.\n",
      "  1.          0.          0.0748472   0.          1.          0.          0.\n",
      "  0.25755     1.          0.          0.          0.          0.74177343\n",
      "  0.          1.          0.          0.          0.25854847  0.          0.\n",
      "  1.          0.          0.09355672  0.          1.          0.          0.\n",
      "  0.31969345  0.          0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment. As you can see the agent picks an action randomly ( action = np.random.randint(action_size) ) and this action is passed in the environment's step function. Then next state, reward, done and score is calculated. You should set `train_mode=True` to restart the environment. This project's challenge below is to make the agent to pick better action's after gaining experience over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Training the agent!\n",
    "\n",
    "Here we train the agent to solve the environment!\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "``` \n",
    "First of all we import some libraries. We will use [Pytorch](https://pytorch.org/) for defining the Neural Network for this project. Also very important is Numpy amd Matplotlib for plotting the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import namedtuple, deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "##torch version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we define the Neural Network\n",
    "This is the most important factor in DQN. I have used 4 Linear layers as part of this network and I have changed the nodes a lot to find the best parameters. I examined a lot the middle layer and saw that when we use larger values than 64 etc 128 or 156 then we solve the environment in fewer episodes. With 128 nodes task is solved in 383 episodes and with 156 is solved in 419.\n",
    "The Deep Neural Network is used so the agent can approximate the action selection for any state. The input size of the NN is 37 like the state size and the output is 4 like the action size parameter. We use the argmax function so we pick the action with the higher probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed, fc1_units=64, fc2_units=156, fc3_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)        \n",
    "        self.fc3 = nn.Linear(fc2_units, fc3_units)\n",
    "        self.fc4 = nn.Linear(fc3_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        return F.relu(self.fc4(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below we set some hyperparameters\n",
    "These parameters are very important for the DRL algorithm and slight changes make big impact at training. It apperas that below values contributed to faster training.\n",
    "\n",
    "#### Also we define the agent class. \n",
    "The DQN network will use the \"Experience Replay\" and the \"Fixed Q-Targets\" optimizations.\n",
    "\n",
    "In the constructor we define state size, action size and seed. We initialize 2 identical Neural Networks with the same seed so they get the same weights at the beggining. We use Adam optimizer with very small Learning rate(0.0005). Also we initialize ReplayBuffer which is responsible to store the \"experiences\" of the agent etc keeps history of different states, actions, rewards, next states and done parameters.\n",
    "\n",
    "At the step function we save experiences in replay memory and if there are enough experiences in replay buffer then it gives the order to sample some experiences and update the target network with a gamma discount factor to make rewards that are in future less relative than that of current rewards.\n",
    "\n",
    "At the act function we make a forward pass at the local neural network and we select an action. Now according to the epsilon-greedy-policy we either select the highest scored action, or select randomly among any of the available actions.\n",
    "\n",
    "At learn function we take use of the SarsaMax algorithm. By this algorithm we tell the agent to pick an action that maximizes reward in the next state based to the specific policy. Then we compute the Q_targets based on reward and gamma factor. We also get Q_expected from local network and after that we compute the loss with Pytorch MSE loss function. We continue the algorithm with making step with the optimizer to correct the weights and at the end we use the soft_update function.\n",
    "\n",
    "At soft_update function we have a constant TAU. This function updates the target network's weights to match the weights of the local network. Parameter of 1 will result in full synchronization and parameter of 0 will result to NO synchronization\n",
    "\n",
    "#### Last we have the ReplayBuffer class\n",
    "\n",
    "This class is resposnible to store the experiences of the agent which include different states, actions, rewards, next states and done parameter. The add method appends the SARS tuple to the memory. The sample method gets random sample of data for the agent with a specific buffer size. The samples are random so that our agent can avoid memorizing sequences and take advantage of experiences that are rare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "BUFFER_SIZE = int(1e5)  # replay buffer size\n",
    "BATCH_SIZE = 64         # minibatch size\n",
    "GAMMA = 0.99            # discount factor\n",
    "TAU = 1e-3              # for soft update of target parameters\n",
    "LR = 5e-4               # learning rate \n",
    "UPDATE_EVERY = 4        # how often to update the network\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, seed):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.seed = random.seed(seed)\n",
    "\n",
    "        # Q-Network\n",
    "        self.qnetwork_local = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.qnetwork_target = QNetwork(state_size, action_size, seed).to(device)\n",
    "        self.optimizer = optim.Adam(self.qnetwork_local.parameters(), lr=LR)\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(action_size, BUFFER_SIZE, BATCH_SIZE, seed)\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps)\n",
    "        self.t_step = 0\n",
    "    \n",
    "    def step(self, state, action, reward, next_state, done):\n",
    "        # Save experience in replay memory\n",
    "        self.memory.add(state, action, reward, next_state, done)\n",
    "        \n",
    "        # Learn every UPDATE_EVERY time steps.\n",
    "        self.t_step = (self.t_step + 1) % UPDATE_EVERY\n",
    "        if self.t_step == 0:\n",
    "            # If enough samples are available in memory, get random subset and learn\n",
    "            if len(self.memory) > BATCH_SIZE:\n",
    "                experiences = self.memory.sample()\n",
    "                self.learn(experiences, GAMMA)\n",
    "\n",
    "    def act(self, state, eps=0.):\n",
    "        \"\"\"Returns actions for given state as per current policy.\n",
    "        \n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state\n",
    "            eps (float): epsilon, for epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
    "        self.qnetwork_local.eval()\n",
    "        with torch.no_grad():\n",
    "            action_values = self.qnetwork_local(state)\n",
    "        self.qnetwork_local.train()\n",
    "\n",
    "        # Epsilon-greedy action selection\n",
    "        if random.random() > eps:\n",
    "            return np.argmax(action_values.cpu().data.numpy())\n",
    "        else:\n",
    "            return random.choice(np.arange(self.action_size))\n",
    "\n",
    "    def learn(self, experiences, gamma):\n",
    "        \"\"\"Update value parameters using given batch of experience tuples.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            experiences (Tuple[torch.Tensor]): tuple of (s, a, r, s', done) tuples \n",
    "            gamma (float): discount factor\n",
    "        \"\"\"\n",
    "        states, actions, rewards, next_states, dones = experiences\n",
    "\n",
    "        # Get max predicted Q values (for next states) from target model\n",
    "        Q_targets_next = self.qnetwork_target(next_states).detach().max(1)[0].unsqueeze(1)\n",
    "        # Compute Q targets for current states \n",
    "        Q_targets = rewards + (gamma * Q_targets_next * (1 - dones))\n",
    "\n",
    "        # Get expected Q values from local model\n",
    "        Q_expected = self.qnetwork_local(states).gather(1, actions)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = F.mse_loss(Q_expected, Q_targets)\n",
    "        # Minimize the loss\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # ------------------- update target network ------------------- #\n",
    "        self.soft_update(self.qnetwork_local, self.qnetwork_target, TAU)                     \n",
    "\n",
    "    def soft_update(self, local_model, target_model, tau):\n",
    "        \"\"\"Soft update model parameters.\n",
    "        θ_target = τ*θ_local + (1 - τ)*θ_target\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            local_model (PyTorch model): weights will be copied from\n",
    "            target_model (PyTorch model): weights will be copied to\n",
    "            tau (float): interpolation parameter \n",
    "        \"\"\"\n",
    "        for target_param, local_param in zip(target_model.parameters(), local_model.parameters()):\n",
    "            target_param.data.copy_(tau*local_param.data + (1.0-tau)*target_param.data)\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, action_size, buffer_size, batch_size, seed):\n",
    "        \"\"\"Initialize a ReplayBuffer object.\n",
    "\n",
    "        Params\n",
    "        ======\n",
    "            action_size (int): dimension of each action\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=buffer_size)  \n",
    "        self.batch_size = batch_size\n",
    "        self.experience = namedtuple(\"Experience\", field_names=[\"state\", \"action\", \"reward\", \"next_state\", \"done\"])\n",
    "        self.seed = random.seed(seed)\n",
    "    \n",
    "    def add(self, state, action, reward, next_state, done):\n",
    "        \"\"\"Add a new experience to memory.\"\"\"\n",
    "        e = self.experience(state, action, reward, next_state, done)\n",
    "        self.memory.append(e)\n",
    "    \n",
    "    def sample(self):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        experiences = random.sample(self.memory, k=self.batch_size)\n",
    "\n",
    "        states = torch.from_numpy(np.vstack([e.state for e in experiences if e is not None])).float().to(device)\n",
    "        actions = torch.from_numpy(np.vstack([e.action for e in experiences if e is not None])).long().to(device)\n",
    "        rewards = torch.from_numpy(np.vstack([e.reward for e in experiences if e is not None])).float().to(device)\n",
    "        next_states = torch.from_numpy(np.vstack([e.next_state for e in experiences if e is not None])).float().to(device)\n",
    "        dones = torch.from_numpy(np.vstack([e.done for e in experiences if e is not None]).astype(np.uint8)).float().to(device)\n",
    "  \n",
    "        return (states, actions, rewards, next_states, dones)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next we write a function to start training our agent\n",
    "\n",
    "Here our agent interacts with the environment and takes actions that depend on previous analysed functions. At every episode we:\n",
    "\n",
    "- Reset the environment\n",
    "- Follow the epsilon greedy policy\n",
    "- use agent's step function so to populate the memory with \"experiences\" and after some steps we trigger the learn function\n",
    "\n",
    "We continue everything as long the score is above 13 in over 100 episodes. Also a chackpoint is saved after the environment is solved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 1.36\n",
      "Episode 200\tAverage Score: 4.98\n",
      "Episode 300\tAverage Score: 8.13\n",
      "Episode 400\tAverage Score: 10.66\n",
      "Episode 500\tAverage Score: 12.78\n",
      "Episode 519\tAverage Score: 13.02\n",
      "Environment solved in 419 episodes!\tAverage Score: 13.02\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJztnXmYHVWZ/7+n7tJL9p2EJGQhCIlAgBD2HRRBcdxlEB11BkEdmBlGDYyKOqKMo+jPDcUVNwRFhDEKhLCvkgBhC0sSkpB9606n08u9t+r8/qg6VadOnVO36vZduvu+n+fpp/vWeurevu973vUwzjkIgiCI5sVq9AAIgiCIxkKKgCAIoskhRUAQBNHkkCIgCIJockgREARBNDmkCAiCIJocUgQEQRBNDikCgiCIJocUAUEQRJOTbfQAkjBx4kQ+a9asRg+DIAhiSLFy5cpdnPNJ5Y4bEopg1qxZWLFiRaOHQRAEMaRgjG1Ichy5hgiCIJocUgQEQRBNDikCgiCIJocUAUEQRJNDioAgCKLJIUVAEATR5JAiIAiCaHJIERAEQXj89fmt6NhfaPQw6g4pAoIgCADbu/rwyd8+jct+u7LRQ6k7pAgIgiAA7O8vAQC27e1r8EjqDykCgiAIACWHAwCymeYTi833xARBEBqKtgMAyFqswSOpP6QICIIgABRt1yLIZ5tPLDbfExMEQWgokUVAEATR3AiLgGIEBEEQdebxtbvx0Ks7Gz0MlBzXIshlms8iGBIL0xAEMXy58CdPAADWX3d+Q8dREhaB1Xzz4+Z7YoIgCA0iayhHriGCIIjmRMQImtE1RIqAIAgCQYyAgsUEQRBNim8RUPooQRBEc+LXEZBriCAIojkp2OQaIgiCGNK8tKULP3xgTcXnF0quIsg3oSKgOgKCIIYF5333YQDAJ08/uKLz/cpiihEQBEE0J8IiINcQQRDEEIdzXtF5oqCMNZ9BQIqAIIjhRYV6wFcElZ4/lKmZImCMzWCM3c8YW80Ye5ExdoW3fTxjbBlj7DXv97hajYEgiObDqVCS93uuIY7m0wS1tAhKAK7knB8G4HgAn2KMzQewBMByzvk8AMu91wRBEFWhUjEuLIIm1AO1UwSc862c86e9v/cBWA3gQADvBHCTd9hNAP6hVmMgCKL5qNQi8F1D1RzMEKEuMQLG2CwARwF4EsAUzvlWwFUWACbXYwwEQQR84c8v4PG1uxs9jJpQqY9fZA1VGmwW537uj89h5YaORMfv7u7HP9+0Ant7ihXfsxrUXBEwxkYCuA3Av3HOu1KcdwljbAVjbMXOnY1ftIIghhO/fmKDvw7AcKNSOV5y3BOdAZgE+ws2blnxBi7+2ZOJjv/xQ+tw7+rtuPmpjZXftArUVBEwxnJwlcBvOed/8jZvZ4xN9fZPBbBDdy7n/EbO+SLO+aJJkybVcpgE0VQMZMY7FKjUNSROG8jbI+5tJcxBFUc1+iOpZdYQA/AzAKs559dLu+4E8BHv748AuKNWYyAIIkqjhU6tqfTxhBAfSNaQ4whFkPAE77hGZyrVssXESQAuBvA8Y+xZb9vVAK4DcCtj7OMANgJ4Xw3HQBCEgj3MNUGlFoGvCAbw9og2FZmEmoB5mqDRH0nNFAHn/BEElo/KWbW6L0EQ8VQqKIcKlT7eQGIDArG4TWJFMEiqmKmymCCaDE9WDVsqjYGI8waiKEueRcBSxwgaq5xJERBEkzHcLYJKZ/ZOFYLFIvMok1QRiBjBcA0WEwQxOBnuMYJTv3F/JC//vpe34/zvPgw7RktUI1gsVjlL6hoS2UWN/kRIERBEk8GHuWuou7+ER9bsCm278tZVeHFLF/b2mgu3hJKoRrDYSihZh336KEEQg5PhbhEA0WcUM+84i8CvIxjIff300XRR4Eanj5IiIIgmI04YDhcc5RlF8DYuKBukj1b+/hS9SHxiRcAGR/ooKQKCaDIanaFSD1RlJ1z2cTqwGnUEImsoaUGZ7xqq/JZVgRQBQTQZg9U1pM7iB4LJNeS3mtbdvxpZQymDxWyQBAlIERBEkzFYPUPVTGtVlYqQy6XYGMHAs4aKKWMEfmVxxXesDqQICKLJqObMu5pUc1jqtZgfLK6tRWCnjBFQHQFBEDXhgzc+jit+/4xxf70Kyq6/5xV86c4XI9sv+P4juOpPz0e2V3NcEdeQJ+lEeqeOoI4A2NtTxKwlS3Hfy9tT3TdtryFrkDSdI0VAEMOMJ9btwR3PbjHur1fW0MqNHXh6Y3SBluc27cXNf4/236+mfoq6hlyJW4pVBOI3x5qd+wAA37tvTar7+sHixDECyhoiCKIB1MszVCg5ZZWOnMFUVYvAoAiKca4h3zcE5DMZAMGqZUnxm86lbCbXaGcdKQKCaDLq5Roq2Lys0pH3VzVYrFxL+OKTtZgA8llXNKZWBH76aMqCMrIICIKoJ/VSBMWSUzYwLQvm6gaLB5I+ypHxJGMh5ngdpUqDxcN4YRqCIAYh9YoRJBGissCuZqGbems/fTQmRsAli0C8RWktgvS9hnxN0FDIIiCIJqNeboii7ZS1PuTd1VRQJougFJs+KtYjCP5O7xqqrKCMYgQEQdSVelkESVxDDq+Na0h9RpYia4hz7p+fPlictqAsuGcjIUVAEEOAPz+zGbOWLMWOrr4BX6teLSYKtlP2XrVzDSWrLL7y1lWYtWRpaCwcgaXSbztYt7Mbs5Ysxf2v7PDP+869r2LWkqXYurcXs5YsxR3Pbsband346tLV3v30iuCPKzdh1pKl2LO/AIAKygiCSMHvvLz7tTv3D/ha9Zp9FkpO2WUxw1lD1bt30mDxbU9v8v/2T+EIWQQr1ru1EEuf2+ofe8MDawEAL27uAgDc/PeNeGZjp7/f5Bq68SH3vO2eQhfjanSxNykCghgKeIKiGoudp0yEqZiizRPECOpVR+D+jncNBb2G5LEIq0ZeflIIenGU4wBtuYx0P/0HJRbGGZEfXHk6pAgIYggg0guroAfqWEdQvqCsdnUE4dcswcI0Yp/jhM/3F5uRZvkZ5Xo258hJVWQmq6urt+SNL7y/0emjpAgIYgjAfYtg4KqgHk3nbMcNuJYT7rJgrmqLiYhryP0dV1kcrFCmWATeGLOyIsgIl467r+Rw9EuBZdNz9xbt0H5qMUEQRGKEnKiGa6ge/mjhiy93r3q5hoQrx+Qa4jwQ/pyHlaW4VkZjEYhzbMfxhby7PX58Yn81LLxqQIqAIIYAQuAkXfkqjnpkDYlisnSuoerdP5I+ivjKYjmeIReUuePSKAIrfD3bAfpDiiBZbCTIGqLKYoIgyuDPIKvhGqqB0OGco7doI5exYDscRc9NkqaOIOwm4ti4pwfTxrYhl4nOV/uKNizGkLUY+kp2RInYDkdvwUY+ayFjMV/g9hVt9JfsSDaT68YS9wb29RUj45KFv0hD7S8KRRC2CMRj2Q53s6c4R6sUTFYtgkYXlJEiIIihgJhBVuFStYgRfO++Nbh+2as4YHQrtnX14fGrznTvVWEdwZ+e3owr/7AKFy6eia+/+/DIeYd+4S7MGN+GdxwxDT/0UjllSo6Dw754F957zHR8831H+lk837znVXzznlcjxxcdx7//vau3497VwToEtjJ7P/+7D/t1AH2e8C85HH3FaIzg839+wW+5ff4RUyP7KUZAEERighhBNSwC6bpVkkB3PLsZALDNy48vloJsmjjk3fK4du/vd6+3t9d47ht7enH7M5u1+wre/f+40q0TKNf7pxTTKbWn3xX2Ilj86vZuf1+fZPkIi2DyqBZf0N/yVLDuwqNrdvl/O6priLKGCIIoB1dcCQPB1gRCB4qqoESMoHxBmT5YLFwv5RRf1tD4X214V07flRxzXyShlDKasfQWZIvAxqjWLOZMGuErFbmewAm5vsLXoYIygiDKUs0ZI9cI3IGiikjRo6d8iwn5b0lB2clcYVnDVL9QskOvyym8ks2NLrNd3a4bSLfqWL9kEfQVbbTmMrAY899j+RxdbUKjXUICUgQEMQQQM+s0gV6T28c2zMIHgjpZDtJHK6sjSKqgsoY0qv5SSovA5sZjdnX3G++lxgjaPEUQWATBsTrrR05ZbSQ1UwSMsZ8zxnYwxl6Qtn2JMbaZMfas93Nere5PEMMJISfSTOBNx8rCt1oWgYpQBJzHxyFMdQSqoDSdk9VkFAGBgBaUs0yKjrlB3u5u0SBOZxEEBWK9BRutOQuMSdXI0jm6RXiCWw7fGMEvAZyr2f5tzvlC7+evNbw/QQwb/EVTUkwdTb33Q2sAxPTeGQhy+2Y1LVTGVEcgFJROURWlMecMMQLVIijnGoqrghYZQrprhGIEJRttuQwyVuAakuMKugwp7r+OHV7NqZki4Jw/BGBPra5PEMONku1gc2cvuvtLvvBRSWUReLKwq68Yul4tLAKmePM37ukJxsGBzp4C9vYWQ+PvL9nYImUF6YLYOuEs5+t39hQj+4GwInpjT09ZBeouoqPf191fioxPIBROZ08RnT1FP0awq7uA7V192Oed6z4LIn+Lcb22oxsbdgedZbft7YtYNbWkETGCTzPGnvNcR+NMBzHGLmGMrWCMrdi5c2c9x0cQDeFrf30ZJ113H958zd04+r+XhfYJOZbGpy8sguOuXR66nqmIayCoXpMlf3o+dL+FX1mGI798T+je/3HLKnz0F0/5r0NBbG/WrxW+koCUFY6MLERP+cb9WLVpb+z43RhB8poH3X2efaMTLbkMLAZs7uzFcV9bHjo27BoKX2vlhg6c9r8PAHDfh+O/vhxX/P6Z2PFUk3orghsAzAWwEMBWAN8yHcg5v5FzvohzvmjSpEn1Gh9BNIyHXjNPeJIGFblGyPcqM0tdi+VaYgoI3/3iNmVc8jnm9FO5cMtEkmNk3PTR+GO0riHlvc1aLFGtR9zn2dXnWhHLV++I7qwRdVUEnPPtnHObc+4A+AmAxfW8P0EMZnR56gInYYxA52ePO6YunUgTZinpFJROUanCV0d/KZ1bpZRg7QTdWNRYhMVYon5QcqfT8HaOzh7XjTeytX6NH+qqCBhjU6WX7wLwgulYgmg2dHnqgqRZQ0ncPvUoKJPhkqyMk7W6sevGl8R3LoK4SSk5+vTRfDYQkTqlqVoeFku2XrHJInA40OHFPUbVURHU7E6MsZsBnA5gImNsE4BrAJzOGFsI9/96PYBP1Or+BDHUMGRCuiSMEajVuToLoh4FZTJJLYJQHUFMjCCJRZDkGBnTIvUj8hl/n+69UpVSxmKJFEEQDA9vdzhHh7AIWnJlr1MtaqYIOOcXajb/rFb3I4ihTpxrKLAI4gV3qHePw0NZK4K4oGUtSHq/aloEafWb6uIRtOez/gxdbxGEx2JZav5UGMZEbYX7Ouoagu8aGtUyTF1DBEGYMS14Dsh1BPHXUC2Czv3R9Epdq4OBEjcJDheNmY/TxTfKZepUC7U3kWBES9A62ubRNhQRRcDiLYKc1xLD7Bri6PA+s2EbIyCIoUZvwcZLW7pqcu2uviJe277Pfx2nCIT8eXpjR0gYvbB5b0gYqZk3ws0Qvlb5GMGWzl5sjen8qRKnCGTX0Nqd3cbjklsE6TKCkmByDbVLi8zbTlRhdCh1DBkW/zlm/SUu9fu3dPZi9dYu794Z/UE1gBQBQcTwH7c+i/O++zD29uoLlwbChTc+gXO+/ZD/Om4mKVwI37tvDX7+6OsAgK17e/H27z2Ca+540T9OtQi6+nQWQXlXzYnX3YcTvn5fwieJRxbm7/7hY/7f6p11y0PqMnVqYhGYYgSSReA43LjCmaCca0j0KzJlgZ35rQfxB691dj3cdgJSBAQRw1Pr3eL4tOmISXhRsTRiFYEkE17e5loRolp41aZOf58sTEs2186oZVlWq8pimXKtqP3jdK4hXYsJZdvY9oEHVdVupYKQRcC5UWEILMZiuwaJLKQkrr5ijdp/6CBFQBAJiJ/nVQdTb31A6Q+kuE3k89S2zrpZZcgiqEMdgWlmqz5t2DVkztQpKbPy1uzAXSgmoTtCcs/YDjceN9IL7GYYi427ZP0Ygfs67t2vVvwmCaQICCKGejYDi7cIzP7zjNSTX3UN6WbjOhfMQEkaI4hDl9aqU1QlRRgnKeAqhylY3JJVFYH+ONH8zrJYrEsniBEksQiqHwsxQYqAIGLwv7A1bBPsd6pMUFAGBMJbCMtsaPGTsJDXCSVZMFerxUScLE5qdeiymXTjKyrarRrLd5rSR+V72ZwbjxPtsDNWvG8/7x3nL0wT83+lKrxaQoqAIGLw8/drODnTLWsYPUaeLXtuEzuqQNSiLJ0bKNxiouJhh4kde7JL6LOGoseprbOroAeMvn95e1ywOOd9BlY511AmvFh93HtjaiNeC0gREEQMlXT9TIvjWwTlxwEEwtFOZBEE5+ncLdUSNrGVxQOwCHTvuxosroYiMAl4dV0FoyLwgsCuIjDfJ6vUEcT5hmq1aJAOUgQEEYP4wgrBVCg5WPbS9rLnrdywBzu6+vzXnHPc/eI2OA5HyXZwj9R5M/D16yXa8tXbQy4J23Hwwua9eN3rX//85r14dM0uvLp9nyL4nZAQfmr9Hmzb2xebPrq7ux9/fz1YRqQaMYSkSpRzjpe3dWHdzm5fCNoOx579BTy+drd/nBosrgZ/eW6Ldrv8vjuc44l1u7XHCWWcKRMjELGEu17Yhs6eAh5es8t47NbOPvz04XV4w9Bqu5rUr3SNIIYw4sv99b+txi8eXY/bLjsRxxxkXE4D77nhcUwYkcfKL5wDALjt6c34zz+swlfeuQD7+kr437tf8Y8VciOjWYh9U0cPPn7TitC2ksPx9u894r/e11fCRT99EgDw8GfP8LerMYKLfvokJozI472LpkvHhO/33h89jtd3BQuk9JfsUAplJZiUSaSOgHOc+52HAQCHHzjGP/cDP34cr+3oxrqvnQfLYpGZcjWMmu1d/drt7180Aw++uhOTRrWg5HD85omN/r6sNJZcRlgE8YpPHHfPS9txz1eWGY8DgG1dffjq0tU4ZMoozBjfnup50kIWAUHE4X2nhTATuf9JMjp2S6uCbfesg217+7CpIzzD811DGoNgX1+0V1DSxm1FzYLsu/cXtKmoAlkJAMm7eMa5Z5JaBLr6BtvheG1Hd2jbQIOo/372ITjr0MmJjj3/iKlYf935OHBsG2yHg4OjNeeKTTlt11cEFov1+8elCJtozdW+wpgUAUHEECyi7r7u8iqMRw6gIZgqF23lHv69Ha7tohknCG0lRqAvKDO7hlT6yhRQCWKzhgz3iK5fHK0jUJ8HiMY10qzjDJTp8mo8x3X5FEsc49rzAAJ/PxC4fDKMxWZJ5Sq4eRspAoJoLH7WkCdsxAw9TvaUa/2s7hb9+tVUSYdzbTuFOL+9ml2kCuHWnJVqqcrkFoFZFZiMJ/XW8rP6wWLpIJHKqRZ1pQ1jWFZ89a8OUShWtB1fMMsxHaEUMla5grJKLILai2lSBAQRg5CZ4sstLIK4/Pu02R5+QFoj4LSKINY1JAlOjWtodGsuVUFZNfr6JHUN7e4OXGm6OgJhCanB4rQZXXHtvk1YlhuLKNgO2rxqY1moi0syVi5YnF7kkmuIIBqMKPjxLQKvv3+cANW5boRsYCxaRGRaltHhHL2F6HQ6zvUQyhqyncg1R7VmU7WhTqoIqlFQtkeKqQhlypXnkfcJUs/uyzSGM50jeg3pLAJRA5IhRUAQww+/jkCRx7GKICaNRSeC/DiEmg1jcA3FWRyRFhOKUBrdlktVWZx0pa9qtJiQFYHu/fWDxaoiSB0jSG8RZCwLJeEa0lgEQrlnrPj/jVwFweK2OrSjJkVADBrueHYzdnW7aXxv7OnB3VKufRLW7OjGA6/sSH3f21Zuwu3PbMI6Ta988ZW2OccfvfbAALBuZzfue1lfT6BaBH97fiu27JVrCsLHO4YYwf+t2qIVxLExAjnzxnYiymV0ay4kOH/zxIbYjpqbO3px/T2v4Nan3sAjr+1Cf8nGb57YgJ8+vA7X/e1l3PjQ2rKCOGktwu797mfPmF7Z/fqJDeCcR1xDaWv9MhXFCIBiyYHDgxl6VjO7Z4whLqlJd045WrO1F9OJUx8YYycDmMc5/wVjbBKAkZzz12s3NKKZ2NHVhyt+/yyOOWgcbrvsRLz9e49gb28R6687P/E1zr7+QQBIdc7and248g+rAAAXLp6Jr7/78PAB3pf65a1dWPKn5/3N4m/dveT+NJxzXPbbp/3XrmsojFq0Jvjcbc/jM299U+T6yYPFPBLEbclasB3u5bsDz23aixsfWotPnzlPe73bnt6Ep9Z3+K8vPW0ufvTg2uBZOPCW+QdoLZ3j54zHE+v2JBbUIhDflston/GGB9biyOljI8HiJW87FJ/543PJbgLXjfPPJ8/GfS9HJw2mYG/GYujzWlUL15Au8JuxymUNpbMIchlWkfJIS6I7MMauAfA5AFd5m3IAflOrQRHNh1h1aps3c67FQjA65KyYPfujRUVCsKZZDF22CHRCJWIRSIpg0UHjcM075vv7ususORx3bZ1ryOEcthP2Vce919uk6mgA2LgnqDM4801uLn7BdiJBgkmjWnD1eYeVHa9MufcNAHZ294dcb/943Ey8b9GMRNcXZCyGEw+eiEtOnaPdp8NiDH2FsCKQdaxQhOViBFlN0WAc1WixnYSko3oXgAsA7AcAzvkWAKNqNSii+RBf7koKbqqFuuwgkD4QCah5+uWP911DDodlhde83adZYSxxjMB2IgLVdjg4534XTMBNpzSxQ6m4lZVGi5fWqCuuYwgCqEljBMKS4twdpy7usL+/FHqmgfy3iOvLwt+UUeRaBO74hM9efioRI6h2QVlLHQLFQHJFUOCuI5ADAGNsRO2GRDQjoqeL+kVMGwgcCB37o+v7BuNIfh1ZMKqzQ4Zo1lBQtMaRYSwkmLt601kE8v106aM2dwVzTvI7x3U9Vdsuy+MRvfpLNo8IZCat3Zv0MxQWgcM5So4TUlaC7r5S6P1NkwkqrieG42f6yIrAZBFYzA/ci1XGdLMEi8VnSaXNGsrXaWKUdFS3MsZ+DGAsY+xfANwL4Ce1GxbRbAjXizo7raTpWRrlIR+qtQj89QiSI2bs2r4zGsklu4YyFgsttFJuzeG4fbqCMsfrSJoNpT6an0VFzuxp8QSizkJhCCybpD3i/B79nkXQogmS7i+UQi6kNImgqn9ePHeS9yJrMf9/VKegBCLNNOkYypGpkyJIFCzmnH+TMXYOgC4AbwLwRc55fMckgkiBmG2pFkElzS+LNkc+m+wLJM/OO3sK4DwcYK3s/p51Y3ITmGIE3FWE8nvQpfHfx7uGwsepQqnkuJlE8sw0TYHVzu7AVSRmxiXb0c7MxS2SuoaEe5CDo+Rw5LMZACU/sA24riG5DXUqiyBrYb8UE5L9+sGYDa4hxvxJQz4mi8eqch1BLmVMoVLKKgLGWAbA3ZzzswGQ8CdqQp/BIqhkHYCC7cR+WcPXD/4uORzd/SWMao0uhm6naHEpZrbMsEhJNGvI++1wZJUYQVdfCePacyFrJT59VI4RRF1DjuO+p/L7ExcjUJFTTWWLQDczF8+RtKAscA25VoFwi7Tns37QfH/BDqWPppkv+wvHC3++iBFkZEWg/7+R3yMhzHVPZVW511C9YmZlFQHn3GaM9TDGxnDO99ZjUETzIbKG1JS8SlxD31n2Kka2ZnHe4VPx5LrdmD1xJIq2gzM0HSdVAd/ZU/QVwTMbg7RJ06LlOsSxWYtF3FQ/f+R1LJg2OrStUHLwnXtfxd7eIqaMbg3Nctfs6MahB4xKrghkxaYLFnO3EZ3soqik5QIQ5NNfc+eLWLMjXIPBWKAIfvnY+kTXkzuOAoHgbs9nfEWwr08JFqcYu4hpBFXeOotAf658jFCAOhdkxoq3gNIWs6XNMqqUpHUEfQCeZ4wtg5c5BACc88trMiqi6RBpnNWwCH76iFve8p17Xwtt1+b8KwK+o6fg935/1w8fk45LbhGIGaubShje191fwpPSwi+Au0jJ9+9fAwA4bOqoiLCYN2UUxrTl/PPiZpyhXkOa9FGxapk8801jEcgIgagqAcCdqU8Z3QoAePaNzkTXUwvFhOBulypre/rdYPHi2eOxbW8fPnLirMTjDSwCF6Go5Oc3Zg1JinP2pBE49IBR+Pz58/Ghn7nrQAiLyGIMX3/XEf72yHUM1584Mo9dUq+lUS1ZTBiZxzsXTkvwZAMnqbpZCuALAB4CsFL6IYiq0OvHCMLba71sq1oFrAsY646LvaYIFpfpRCmQlUxGcQ0BwJXnHILf/cvx/msOVwh/4rQ5kXbYoT5CNo8oIoe7ykGe+Va61GOc+40xhrZ8Bp8+42B/2/ulBXF0qLEPIaDbpIVxbO7GD6aOacVDnz0DsycmT2BUg7ziuWU9aCreykkHjchncde/nYqT5030twUtJhhOnjcRb5k/xd/35gNH48CxbaFnUvnf9x0Zer1w5lg88Jkz8InT5pZ5quqQNFh8E2MsD+AQb9MrnPP6VPwQTYEfLFZdQzVOHy1GXEP6FNJUFoGUNZQkg8kKZa2wiGBuy2dCwsrhru9fl/YZSh91oi0mxKplIXdIGU1gqrZtSVDslNH41nXo2kqIM2WLwOGuUq7EZZJTFJflK4IEwWLN2gM6xLXUt1T8H5jaUKtb41J6a0HSyuLTAbwG4AcAfgjgVcbYqTUcF9FkGBVBJWk7KVBbP5tqCUwxAp2gL5XLGlJQs1bU96A1m4n4wh3u5u7HLe5SsvWuIVtpPVFO6Ixu1c8XdemdKrLQjLMgRL9/HSFF4Lg1BpX09W8RiogHwXwgmSJI+hxCqZvSWk0WgfoZVNIYbyAkVavfAvAWzvlpnPNTAbwVwLfjTmCM/ZwxtoMx9oK0bTxjbBlj7DXvt3nRV6KpEMHiyKItNbYI1E6hRteQwUelG55QGhaLzykXqAVNqlBozYe/ppy77iGLRZunhVtMOBFF5FYWh+9Zboyj26JZVEBQWRyH7GqJy7+PU0byCl22w12LoIJsGlOMQMakYOT7xdYR+HGHYBvn+sC0jDqWOuuBxIogxzn3V9vmnL8Kt99QHL8EcK6ybQmA5ZzzeQBi8oZ1AAAgAElEQVSWe68Jwo8RqC6YNK6hSmZR6kw/rWtIF8wWSqNcAzIdGRZVBKrgsT0/v+5x5Vm11iLwsobkc8tZXaM16bRAfB8c8QiyYI2PKZjvH3YNua2gK+nrH2T7hO8pC22TggkvSxmn0LxrGywC06nqZ5kmG6oaJH03VzDGfsYYO937+QnKBIs55w8B2KNsfieAm7y/bwLwD6lGSwxb+nxFEHVlJKUSd0FSi6BQMriGdNeULIIkWU/RYHF4vyoUSrYTmmXK2L7bw2s6p65x4BWZycqmXCB8lME1lESwhxRBpRaBFCx2vGBxJZ91Xkn71MYIDONIqtCsQBPo95ueU/3MjXeoDUkVwWUAXgRwOYArALwE4NIK7jeFc74VALzf0cRuYsjyk4fW4e+vq7rfzBPrduPGh9yWxsIiUHvjCzm9ftd+XLv0Jdz/8g789skNAFyB+KU7X8TWvb0AkisCzjmuueMFXH3789r00e8ufw3PbQqnPJpcQ27gluO6v72MNTv2eccG+fCf//ML2vNkZEWgNp3T39P9LdpAy/g5+BkLRVvjGvLGK1tPz2/ei4//8inj+gqmxdPjgsViRiy7htRgrUzcRzcir7iGHF5R6wVVgFspYgSh50jgGjKNLq67aSNJWkeQBfD/OOfXA361cUvNRuXe4xIAlwDAzJkza3krokpc+9fVAJKvB/DBG58AAFxy6ly/uZnqghEz6gde2YGfPPw6fvKwWyNw0XEH4fF1u/HLx9Zj/e79+OVHF3tf1vLtonuLNm563FUmM72aAUFnTxHXL3sV1y97NbTdNGvmHNjVXcCPHlyL25/ZhCevPtsPFm/r6ou0cdYhK6MMiwaLTeiEh3j/8lnLdw2NbMniLQumYO2ObuzqLnh9fIJz713tKoD2Fr04aDWskGWKEbzn6On42MmzAISDrHHBZd2zfPKMuVj63FZ89OTZfm1IwXZQKDloz4XHev37j8Su7n587a8vAwB+8U/H4qn1e/DDB9b6x1x5zpvQV7TxnmPcNFZhUcm3ll1AX3h70A48Z4gRfP3dh6OvaPuLKInPTn2eS0+fi/9btQULZ4z1tx00oR0bdvcYn7+eJLUIlgNok163wW08l5btjLGpAOD9Ni4nxTm/kXO+iHO+aNKkSRXcihhKFD1FUDDECHT9dYT1IL5CSRt6FSU3j7wUZEvW8ldIi9zLECPgPLBEeryiuGLKuEBBcQ0llQk6fSEUlliAxuFuFfH171+IQw8Y7QeQ0xSRmS0Cvfj41vuPxIJpYwCEBWucxaZ75smjWnHDh47BhBF5f9ser+hq3Ihw3OLdR0/HJacGOfdnHDoZnz330NAxU8e24scXL/Irx8Utdb2G3rpgCj5+8mzt2HOSEr1w8Ux89KTguGAR+/CzXHz8Qbj1EydgzqSR/ravvytYBKnewWGVpIqglXPulw96f7fHHG/iTgAf8f7+CIA7KrgGMcywvbVgAZ1rKNx2QEYcK0z+pDNpWfDKC85MHNmCHfv0ikCtevXHx4O2dWI8pmON4ymFFUHS59DGCLz3KZexUHQcLzAsMlkYbK/XkO4WpsB2q2Hmn6SOQA6+xgVAdYpJKHb5/RBN48a25yPHlx2Lcg9djECMV52hJ81+EmNN9AlKBzXYIEisCPYzxo4WLxhjiwD0xp3AGLsZwOMA3sQY28QY+ziA6wCcwxh7DcA53muiyekr2r5wFgpBfDGEbNJaBL4bRCwdmOzfWVYEfVI3yomjWozBaVPHT1GpK183be1DucpiE+6yl+F7iQK5wDUkpS5aUmVxjBJRMWUHJWnsJ38mcc+l2yd88TpLYlx7uaTFKKoi8nP+pc2+a0e5pzyGOEWd0cQdTMjHqGOrbdJ0lKQxgn8D8AfG2Ba4Y5wG4ANxJ3DOLzTsOiv58IhmoLdo++4a4S9ncP/R7AQWgW7mqEO0mC5KM3BRvwAAk0aaZ5mmBd4dHsQxROA2TYM693gpWKypLDahEzbCNSSCxVxqJyGKtmwnPuNIpc0QI0jSrC5sEZiP0z2LUDS6sY6rwCJQEVeVry8EvvpsskUQm9rJlN8xyM88qGMEjLFjGWMHcM6fAnAogFsAlADcBeD1OoyPaAJki8D3+4sWxoaF3YFA4ApfdbkiIzGrlwWvWJAcACaMCPIfVJ1ibDHBo/2QBuYaSt4NVKf3xDhzGcuvIpZdQ47DQ8pBxuwa0iuCJAZY0gVwdPviXDBjK7AIVILKYnkc0W1A+gVl5DoCUwaxfA/16oMtffTHAESFzQkArobbZqIDwI01HBcxxEhbOCXTV7R9YVjwZrHiixBvEbhCPM6FICNmy/Lyi70h11Awy1RnaElcQ4L0weJw1lDSQC4DiwgZMc581vIWrw+eJeutniUrBxmTRWDSS0liGUln0lrXUIzrqRoWgS591I8RRFxDCb3oSrFaHGnafNSack+X4ZyLxPAPALiRc34b5/wLAA6OOY9oMnRC5IcPrMFvnthQ9ty3fudhvLS1y3/9gRuf8AXax375FP64cpPfpllGWAS5jIUf3L8Gr26PtkMOHe9EU1TVYLFAfRqTu+ejv3wqpFjee8Nj+N2T5Z9ZphSpI0h2nk52lKT0UeEaEjLMshh6CjZe29GtVTYPvLJTex/TKllJLJeclUzY6Z7ZNAvPZ6xQtXGlBMHiYJsQ+Oqzpa1aT3J4yCJocLC4XIwgwxjLcs5LcH37l6Q4l2gidDP2b9zldiX50PEHpTpXLkrbvb+A//zDKu15BckN8r93v6I9RkZYBLJQ75diBLK7IVhlzDXtTa6hZ9/oxEtbAiW2YkMHFs8ej13dyQvrhDV0/JzxOGf+lJCr6JZLjjedphWsBcldplYRZ5QZ6Lc/cCT+/Rb9ewsAv7/keKze2oUPHjsTmzt7IwvMpLUI4g7XWQstmUDYf/mCBfjjyk14fvNetOWjTfgEX3rHfBwh5epf//4j8fK2fZijaVcdpHpGYwSqNZLYNSSumcC5M2RiBABuBvAgY+wOuFlCDwMAY+xgALRaGeFTyQIyA0UunhLE+Y5FdbAsaOUYwYh8dG7zOS8XPc7vr1Ydf+kdC3D2YVMMR0cRz/GTDy/CgmljfKEwqjWL4+ZMMJ5nsajlIp6tJWt5PYkCBRBqbseAdx01PXZmfeys8fjoSbPRls/gSxcsiOxPoggyBovgstPDffZ1Roecr/+RE2fh2FnjAcS7AP/ppNk4embQy/LdR0/H1ecdhg8ujhalamMEYg0EJS5iWqfARBK5Hs4aSnX5qhM7q+ecX8sYWw5gKoB7eNAK0gLwr7UeHDF0qHW7aBXOeaSgDIgv/w8sAn2MQF3kBQBaPSUTlwmkKsFcJrl7BwhiFr5bwlCdqsJYVBMEiiDj1gw4XFqAJSqU4/oMlXuGJLGMnCFrSP2c4tJHBX72U5Wqr7QtJry/1dqJXMp7JosRRMfSKJKsWfyEZturumOJ5iXtSmI6xdGez/jVuWXvx4PUT1kQx31hhdAzFZSN1DRXa/FmhnEL06i70tQCyNcWs+JAcMefp9vf71k4LVnLD2RbGotACHFTxbQ7jvgBJEofVeoIxCI3ecXVkqQltBhzJQ3ndIir6O49cIsgrWso1eWrTn1WRiaGPXHtouU2DnHbRhh63egoOY7v1pGVStwXtqhzDUkxAl2aZD5jIWOxWEWgZkzlMlai1EqBCIwLoRmscpXAIlDol6qtg2Upda6hgUueJDNz2SKwGPNTQtXZvm44kQIwodAqaDgXh3wb8Tmr/wtprZAkR8v/I40uKCNFQFQFU3dOwO3oqdKrUwQpMkFsh/tVwWFFYP4K2po6gn5pHLqZZi5rwWLxLhRVCWYzLFGwUCAUk7h90jYFOuEpt91Qi8fCFkH4vEqycJJYPeEYQdCoTlXYSRSTOKaSZSrjkJ+jYFAEiYPFmvRR03+O/D/S6BgBKQKiKsS5hjr2R3v8D9wi4FqLwJTqCAQKwJQ+qpv15TMWLMYiaxurY5HJWlaqL3bRdpdeVIOX5a6hzRryq62tSPGYmjUkk+a9FyRx0eSUOgJhEahnJmrJYIXfn4Hiu+Ckfxmh8FVFkFb5JMsakv8OH19vvUCKgAAAvOuHj+LWp97Q7vvgjY/jpw+vw5+f2Yxjr70Xf3t+a+SYONdQZ08Ba3bsw9H/vQzb9rptmQeqCGyb+4Fe+d5xFoEfI5BcQ7IQ1ymCXIZ5riHz86nLabrB4nQWgS67ppxryM0aCt+7v2T7Y7aVGIH8rOr4dIHyciQJFqstJg4Y06o9LlmWjfhdZdeQJHbFJEGNEZSzCMZ4y3mKDLYkyipcUJZoqDWDFAEBzjme2diJz972nHb/E+v24KtLV+Pxtbuxc18/Vm2KZg7HVRZ39BTxq8c3YM/+Au56wVUiQrCe8aZJOOtQd32iNO6JksPR1VeK3Ds2a0jECAxCXTfrG9Wac9ce9u7xRalHvUANfOtWGZP56j+8OfS6YOsVQTnhIAsSscB8f8nxLRKHA7bUdE5tbidTaYHWrz++GJecOsd/fdtlJ4b2q8Hin3x4Eb58wQLMUNaBEM88Z+IIfOLUOfjm+46M3Mtf9KXKQlO+XuAaUjOW4m/6P+85Av913mE45qBx3jXNx//yo8fi1k+cEGsR1BtSBERs5ojMHs/Xr6sZiEsf7egpBAFRT1CLa3xw8UzMnez2aE9jfjuc+7EH2SKIm7np0kdldF/2ce250Bf2A8fOiByjPnvOcyeZuGDhtFCBU9HmeougjIOAIehj8+kz3UL/Qsl1M2WY1FfIu4xsCanDE9bYpFHm9aZ0j3TKvEk4ca5b6zBzfLsvCAVqr6Epo1vxkRNnaTKC3N8tuQyuOu8wvNdbPCZ8TLL3JS2hGEHJZBHE/2+Obc/jX06dkyhb6PQ3Tcbi2eMbLvxlSBEQocyZOMTC7rrZfznXkCjIEgJAuNwtFrhR0mTolRyOTm99YVmuxykToYxMnUR1imBsez6cbaM5RlUEsr9fex9ln62swRtUvBovASAswISgKtgOspJrSO4rFLII1BiBZxGkzZcHgvdEN0HIZqIKDoi6lZL8D/hB9GrHCKTriayrlkj6aMqsITlYbPhuxL0f9YYUAaH11+sQC7vrJv865SCEW0dP0Z+NC4tAKI6MVVmhULHk+IrJlgK5cV9YXbBYRq8IcsbqWIEaLC7nGspYLBINzFhyUNX7bb6EOxbp2ysUQX/RQdazSDhHSBHIlp8qeIRFkDZf3h27ey2dvAsHi4PtqkUQBMrNTx0E0WtnEfRLldkyaYPFSWb74YKyVJevOqQIiMSKoDPGNaQKQ865v012DQnXjZhFW4xJLRCS/zvu6Sn4CkkO5MZlsugKymTUc0e1ZJHLWGWDeqqFwVh8sDhrRZ0b8r3F21s+WMz8ULF4Xwu2g5xU0GY7QdM5dd0DGeEKiXOtmfaIz083880alKiqdJMI+Vq5UmSlKNKJK04f9UhytFVmglFPSBEQ2px+gfzl7vQtgvIxAvllZ0/RD9QGs0fuvxZfiDTftd3dQW1Cv9QvKD5YHLiGdApDFU5jvL5FujVtw9eNKpY4naa7RkajCNJMQsWMtVBykMkw38oqyhaBwSUm3z/u/TMJ6cA1ZN4HKO2eTa6hcpYUqp9aqXUNZdMFi1XSZEEB9U8XVSFFQMTGCOQvtxCkusCwqhxk4djRUwhcQ57A0lkEaWZF8iLzcgfRJFlDRdvRLsiuCifR8172TeuEoS61NG5mq9snCxrxXpYLioZiBJ7g6i/ZyFmWr1yLUmqqrAjUtFNxfJLlJyPjEMpdUzplsqZU11SS/4FggZ3UQ4xFfp/9Fh1qr6FM8rRQ97jyB8YtVVlvSBEMEj79u6fxju89ot3XV7Qxa8lSY56/jn/51Qq894bHEh3bG9PfRzfb/e2TG/GJX68IbVOVg/y6s6fovxbCVsQILMYw0ctUmTxan2Ou46o/Pe//Lbt6ksQICiUntPziQRPcVMaMxbSdTIXgMVW/6mIO5QTGyNZwl1RZCYkxzBjfFnsNNw7gLUTjPfeu7oIbLJZcQ0LITJDXW1BkdlC1W0Gw2HcNxR8nCzv1LkHgNkYR1CprSJKCU8e473mk15B371madtZaEgxxMMUIaE2BQcJfnosWaQnE7Pc7976K92vSF3Use2l74nvLrZhVTAW1d78Yvr5qEciKoFBy/FW7fDeCd92MxfCBRTOQsRjOOWwKfvTg2sTjFsgWQVxQb59Xd9DVW8KYthx27HPf11s/cQKe37QXjDEs/4/T8N4fPYbtXf1+kVXenw26Y7/z0yfh3tU78N3lrwHQt58oJ6y+csEC3P/KDnznXvcaskUwbWwbfnjR0X5apuD2T56I7V39uPQ3K917hIKvVuhvP1PIcXwh85m3vgmPrtmFl7ft84P7y688DTu6+nH3i9vccwcSLC5zXFzefJLZfu3qCIIL/vyfjsXTGzswSlXUGQs3XnwMFs4cq56uv2YCTRBuMUEWAVEGNeOm2vSltAh0qJNiWRG4PW/CBzi+ReDO9N6/aIZxkfQ4LBZWZHFBPdHqoqOnEFrqcMroVpw9310/YMb4dpzpFbiJWaEYlxBSR0wfiyOnj/HPr8QiOHLGWFx+5jz/teqDPu/wqRirLMd41MxxOEK6r3xKKE3TCmbPRduRWitn/Px8YZHNnTQSJ8yd4N8/bp1gY7BYifuYiAuO+quoxaXdiu6ssXdJjhDE8j0njWrBWxccoD3+LQsOwORRyazWtDGCRlsEpAiGAEIYp81lTkqcRZB0nQFVYchZRCWH+8rMX4xeKALpG1CuaEdHPmuFLYI4ReBlPXX2FGMXsBGCTeSSt2bd35mQTzc4XpeFlGSGxwyCPI5wvUGQNSQL8JIdFJGVbK746fVuHPHMceMwPVJcsDh0fsy1dK2yo/dn8QOpkFp8q5Jck2IERCpEMLdafdhVegvJG6qZUA0HW0oXtR3Hv464nHBNlMvIKUcuY4WyhuJcQyL9VbUIVMQ1IhaB4Yurcw0lyyNnvkxL2hbaNKuWrUU3ZVRYBFw781RdeeJalSjjQLnE/68wgyKV9yUpxKv2t6AWMjiZRaAPpDcCUgRDAJHnX+32u+r1gfigbxxqZbEQ/PmM5VkE4UVkxGUHutpUPmPFpkXKdPQUwblbkTx2hNkiEF9Q0W+mJStcQ3ohXIlrSKBbRjKOkEUgb5dm8iVHbjQX7mNkqgIW8j++jkC/r5IYgXotsa9sIV6ZY4YSLGY9gnpDimAIIPL80xa1pL0+EC0uUxWB6UuoVhaL16IvvlAMQv7Ii8MPBNciMBdKyXT2FNBTsFGwnViLQKRBqhZBxiCEdemjSVsGiPEmVfKmNQVkBVGUmtiVbK61ZFTdJT6XSiwCocziGg8CaksF/b44yyjwDFX3e9CA5bYBkEVApMR3DWm+pOXM8SR07A+Ks4RSENdVFYFugXfdcULwu2vnBjEC7lsE4SyiSsllmaIIzMdu3NODPd6zjotb5F7pSd+aDWcNqX/rLIKksspPTU1sEYT7+4uPX64FsR3uC9Tu/lJIKZkCu1zZnwYxpPIWQUywOIlrqMoFZQ2ehFP3USIdYpaufklP/cb9OOtbDwIAVr3RiVlLluLvr+8JzcxmLVmK/7r9eZjo2F/ATx95PXKvi3/2d1z3t5cjMYL2Fn1mj+oaEllCLTlhEQjXkNgfjRFUQi5jobu/5L82zcTbchl09BT9dM0xbWaLwF+uMK/GCIJj5L8ffHVn5BpJv9hJgqQyaqWuyCKS896LNg8JuYxm3LrqcHk8Wgy7hHIyzUmEJStfWl7/oC2XSeYaqnL6aKMsAUHYUmvgQECKYEhgcg1t3NODdbv2AwAeWbMLAPDAKztCM2TALQAzsdOrURjlfTGFm2P11i5s2L0/kvaZ3iLwYgRO2BJwNFlDALD08pONY9WhpjvKX6g/XHqC//elp80FAKzd2Q3AFe5/u+IUPLbkzMg1xXsg2gwIIRtyDZXtAxR+/ZMPL8KjS87E3644JbRd3EPtf29CjRH8+mPH4bbLTsDh08fgcq8VtRoX+NQZB0fGbfLixAliseuGi47Gvf9xanCON3STcvFjLNJ7Nm1sG27+l+Nx6ydOwIOfOT2RQqxVQVmjkP+FGv1MpAiGAP0pg8VJm8gBQVWxyKMv2Y4bUO0tomg7IYuAsWh7XoEpyCyqZIslNVgcVBbLLJg2BuNHmGfrKqYFzgHg0ANG+X8fMKYF49pz2O9ZD/mMhcOmjsa0sdHqXWERCCUjnjnNDE59rpMOnoADx7bhsKmjQ9uFkjG9r5HrKhbBmPYcjjloPADgnPlu/ntJWd9AroYV41L9+UKGJ7FMZk0cgYMnB+9tucpif9Uu5d/3hLkTsHj2eEwe3ZqojsDfVyWZ2fBZOMUICBO6LJ1eXxEk+2+JayKnIpSGMNXFyl+2w9FfckLjactljP3iTZXFQpj2eYogCBa7v3WuoTR+atVikc9UZ/C5jBUogqz5Hr4iUCyCuO6dKnEKSkbEIXS9j8qhvk1teXe8JccxNnjLGGbvIkCeJBCrfj5B1pDJIojGWFT8NtQxn321C8oEjfIQxcVM6g0pgkGGLvAoAoEmAammT6oWQZzbQSiNUd5ShyWb+/n2RTusCFpzGeM/bFywGAisGt8iEE3nNENLUy+h3ld+FWp7LBRBQbjZ4ha5D/dFEu9fqJ9/mSGqu8spgqSuobibiPfalCkkjyOS6CQ6nsa5hgx+fL/pXDmLIObaSZbnDI4ZWq4h0/siP0WjH6khvYYYY+sB7ANgAyhxzhc1YhyDkTiLwIQQ3Kbj42abQsmM9BRB0XH8BWiKNg+5htpSKALxukURon5BmcE1BKS1CMzzOTVdsSVrYcc+YRHEKQJ3rDnVIggt9VguRqBaBPrjhAKozCIIX1QEtUsON1puQYzAkDWUQCKp9y3nGhIWQdyKqEGwuLxrqNFCs1qEYgQNfqhGNp07g3O+q4H3H5ToqlTFDN9U5SsEd3B8+BunLrKhu7YIFpdsjv0F93oFxTXUkrPMdQRqQZkScC0aWkzohH4qi0AVaNJLNcMml7H8cSRpV52zRCDXff9ki6B8jCD82qTcAotg4IpAvoZJoPrDMAWLE7z3aV1DealFtokks/2hZgmUo9HCX4ZcQ4OMouOgr2iH3DvibzFT7ewphPLAO3oK/j6OqGtIzDZ37uvH9q6+kAXhxwiEa8hxQq4hWTGpFsF+KW1zt1SL0NlT8AV+PhsWcFs7+7B6a5fvztJ9udOs36q2tpCFkZqnnZPiAnHN1YqloD0GEAhYuXCsnFBSn6Hcoi6VKYLw61bJyjErAs81ZJhUxGWv6Jq0AeV7DfnuwZgKcJPbSSaIY5iPISqjUYqAA7iHMbaSMXZJg8YwKCnZHId/6W4c8eV7/G1ihl+yObZ39WHhV5bhBqldc2dP0T+mUHKiWUPM/eIfe+29OO5ry7HwK8vw8Gtu7rsfI2jJ+fcQXToLthOa6bfmMiEBt+CauwG4bbK/cdcr/vaFX1mGXz2+HkBU4H773lfxtv/3MP7f8mj7ZcFAYgRCD+QyLOIbl8cS5xo6coabmz/FWx9BNKiT1wcwDVFkPKUVVpUoAvUeouDw2FnjjBbI9HHuM7z5wHD2EvdddeXvZ1pU5qSDJ2rPWzzbzWqKK+JLsjCN+KirZRlMH+euQ7Fg2ugyR9afww8cU/6gKtIo19BJnPMtjLHJAJYxxl7mnD8kH+ApiEsAYObMmY0YY92QZ/clx/FmnsE2MXu2He5Xxv75mc3+/qIdCP++oh1pedBfdCJxgxXrO3DKvEmRGIFsERRK4fTRfMbSmv+iz7+MWK9AXelJIJa91AkesXbxKfMm4rRDJuGrS1dj0UHjcPb8Kbjuby/jyBljseqNTv/ZAXdxmQ27e8ABPLrkzIjPPWOF3UFxrqHPnnso3nPMdD/t8thZ4/Grjy3GrAlBGqZu5vx/nz7ZVxZphVUlMQKdlXH/f56OSaNasHJDh/acI6aPxdLLT8ZhB6iKwP2dJD6jxhEsi2H5ladh6hh9i+b/fMub8I4jpoVSTlWC9QjM969GFb3MMQeN89+L6/72clWvPRD+evkpodTnetAQi4BzvsX7vQPA7QAWa465kXO+iHO+aNKkSfUeYl2RBbcuRiB800XH8Weye3uDuEDJCRRBb9GOtIRWXU0yvUr6aNHmUrDYCaVn5rKWfr3dGKGnrv2qovvi+6tBTRjhZzPNmTQCY9rcGaU8gxNK8uiZ4wC4wuLAsW2RWgTGwquPxfVtymUsHCoJyozFcOohkzDTW8nMvV70vJkT2v01BNLmhVeSNaRTNrMnjsDIlmzsZ7Jg2pjI+y7+65K45XSZXnMnjUS7odgwYzHMLzPrDuoIzMeIMVbTt657LxrN/Gmj6z6muisCxtgIxtgo8TeAtwB4od7jGEzI7g3dQjBi1luyg549coC4aPOQRaAqk96iHVmOUnyX+os2WnOW373Sdjj2+DECHrpWPmNpZ8LFmMVryq2BqxNY4ksgfxc4D9xMsotHKEmRMWOaNGZSuIaSoI1tsPj9cVSjjiDpvkqvKRhoWxAdLIFrSGiCwSW2y2MKog8mGuEamgLgdu+DzwL4Hef8rgaMY9AgC1JdJ0sx6y3aTmjdXUHJ5v7Mvq/oRGoRdBaBEJi9RRutuYxftVy0w64hWUnlswz9US+Q1ooRtGTjBVxcjMDt1x8EIkU6pyzEfUVQRpBaqmtogC29dacPZKGRimIEMSIx7YySJ/C/iz21yN4Rw41zTVGwuHbUXRFwztcBOLLe9x3MyIJUl80hBLu75GN0v+saco/pLdiRNFOHA10aP744vi2X8V0larBYTs/U+dU551orRlDONaT7UvtdJlkgfDi4v0C77NYRwxOKwKSSGGO+IslabMCmt04Ih9NVU16vguHEnVNpV9ckCqwWboskNQJ8iFoEQwFKHx0ElBMgoxQAABrESURBVGzZIogK1YKnKEqOXuiGLIJSVBEA0aIzQV/JcS2CTNCewJQ+ms9YEdeL6j5SKacIdG6GrO8akjJ/eGAJ5DPR2XMa19BA3ULu2KLbwk3Eak81c+7FbDt+PYDywrpSkqxH4CsCMgmqDimCAbJtb1+oDXIlFJX1fQWbOnrQV7QV11BU0r2ybR927XO7iD6zsRO9heh41KKzjXt6sKmjB7u7+z3XEPPvL47lPFwElNMI0DU7uvHK9n3GZyurCHTBZ8NKVMIiyWn6BJUNSjPm9xeqZPEVFZ0wkoVvjG6sGnHyMO2kPXANxdwv3SVTYUpNlXESpLgSlUGKYIAc//XleOf3HxnQNWxJasgWwcn/cz8u+81KbbBY5pYVb/jtqAHg90+9ETlGtQhuf2YzTv6f+/HY2t1oyVq+ItjfX0Jv0cZoL1tHDjLrirDO++7D+Owfn9M+V8ZiGN1mzh0H9AJVjhEcMmUkAOC4OeMxeZSbnih+A8AZbwpnlJkCcxaTFElVFEF0mzybjauilTl1njv+GePbyxwZJW7Wn9Y1tGiWm3X15pj89bcd7nY3jSvGq5TRrTnvt9lbLdJ5TfUKA2VCiq63teKomWMbct9GtpgYNqzdub/8QTHIwWI1BnD/Kzsx0xMSJtcQAFx03ExcetpcnPKN+7G7O+oG6uotas5yyWWY7xra5Z07eXQruvq60Su1qyjnUjn54In+ughfe9fhOGHuBGzu6DUebxJWQlAz5ua9P3HVWZgyugWMMTxx1Vno7A2e70cXH4P9/bZfV2FyDVlW4BoqZz0kQSeE5U393vv2idPm4NJT5xqv88+nzMY7jpyGAww5+PFjSDe+ON5+xDQsOmi8Xzyn49p3HY7PvPXQigLb5fjkGXNxxqGTMX+qOc30kCmj8OTVZ2HyqJaq33/VNW+p2VKwSXnmC+f4Ls56QxbBIKBksAjUbSXHMfrjZ00Y4Rf0qKmigDlYDLgCWXwJdnoupimj3S+bXIiWsVhsKpxcULR49jjMnjhCK+zFvUz+4JzStviAMa2+5XDAmNbQeS3ZDMaPyPtC2FR0ZEnB4mp84fUxgmCjyGYa3ZrDuJiZJmOsIiWg3i86vvTP6L7P5v25jIVJNRDCgPs5LpwxtuxkY8ro1prECMa05Yx1EPVi3Ih8TZRsEkgRDAJk4d9bKFNHYLAI8l6xF2Ph5miCOIsgawWFYkIRCPeLnHZarvWDXEUs0lF1iqBVrFhl+O8TM3fT7dJkrQSriwWWhm7t57SUE7TCIqiG9WGiFllDw62x22Cg0UtiJoEUwQBQV3mqFNkd1KMJ9PaXCRYDrpBjStGUTFefWRFkLObn1e/ylq6cLCwCybooJyTkbB5RoKYTSLoVv8LX8VxDhvCkzpII0kzDiGpkxpi0QIp+/NWkYLvvWy0VQXyMoPrXJIYvpAgGgG7mXQnyLF+39kC5OgIgcHcYFUFvvGvIshgsFrUIehRFEDe7kS0Cf/atswi848yuIX3WkDxeFeEuUMcnFIHbhlp/TCWUs0oCi6B2pn41YwRJrkkMX0gRDACdP7+y68gWgU4RBHUEpnvmNVW3MuUsAsB1mYh20iIgF3INlfGty0pIKACta0hYBGWDxQaLQKsI9GMa3eb6ffuKdlWyhQTlBKaYJFSjZsF079jK4goVAeXoNyekCAaAukRkEv7++h6/gGx7Vx/ueHaz34kTgN8eWsZ2uC9QNu7p0V43XyY1cl9fySi8hNAWv1uylt+NdPnL2/3jyrqGstEYgU55BH77eEVgul+SNgQCYRF09Rb98VVD1jUyRiBXXpc7hiCSQIpgAJj89Sae29SJ9//4cXxr2asAgG/c9Qqu+P2z+N3fN/rHPLpmt/Zc0Uf+e/et0e43FVsJedDZUzDm9AuhIayR1lzGD+jKq51lrHi3ipzxIBRAnGuonGIyCTpt6qb3Wx3fPxx1IAC3e+kB3voC82LaISelnJg9Z/4UAMBhMemQlZKkZfNg66jZzLzr6ANj9zeqdkCG6ggGQFrXkGgdLXrpd/e7r/d6xV4nHTzBqAj+cfFM/PTh17Gtq0+7P2i/ENbtLdkMeos29hdsHDKuLWR9CFRh/cOLjg7lk7fl3GvIAvhDx8/Eb57YGDpPLHcJBIpAJ7SF39w0qxZZPerylwLtbNdwrbcfMQ3nzJ+ClmwGB08ehSeuOgsTRg68cKicC+U9x0zH24+cWpMYganyOnQMK38MUXsuP2seLjvNXEey5tq3DQp3HFkEAyBu6T0dYtYu/O5CzomZ+Ixx5urSfNbCPK/KNu7aqmtILlBRe/QL1Nnj1DGtGNceHHugZ43IAlhUgsqMlKpCRRZSVpMjWi5X2m93YbC40mQNAeGA7QFjWqsSK0giYGsVKBbPHx8jEL8bL2SambyyUp5KNqNf46PekEUwANJaBCKmIKp1xflCEcS1Y8hnLH/RE+1+zyWkBifldWzHGc5XLYJx7fmQAhFl/3JBmRDmjAUKbaRkEQjlktHECIRryJQBJawJ0zoHumuWKyirNo2cxenWazAf03ghQwx+yCIYAGkVgbAE+v3F6F2hJVJG4/qs5DJW7JqvYpYbcQ1Js2+TIskos/bRbbnQrF0oKHnmIoS5rERGacav8/eLmbJtENrCmrBTWQTVSw1NQiMncf7nkMA1RHqASAIpggGQNmuoV1pOUj5fFJHFWQS5bDmLQO8aaglZBPrrqxaBaqoKN5AsgFs1RWE6RSCuJS8E05YvI+ilTqg6dBXJ9RZ4DbUIpNbcxmPIIiBSQIpgAKQtKBMphcIyEOeLzBydIBXkE1oEaqtoeWZvcg2V81H66ZyyReDN6mUlMqLFbBHI/X3EuSZBL1xDpnYaSXrW15rGWgTub5NFBcgxgjoMiBjyNHWMoLu/hD+seAPHzhqvbb/74pa9eHLdHswY344jpo/BlNGt2NtbxIr1e3DWYVNw1wvbIue8sHkvWrIWJo9qxVPr96C3aOPYWePxl+e2YNteN+Ono6eI21ZuiriWdAFYQT7LjIIc0K/nK14LP76ps2Q5RSCydzJSZbGwQGTloFsuUhyfy1qAlJ4KxMQIvCm/MVisKygT96vT+rCNtAiEIjS9f4C0GD1ZBEQCmloR3PvSdnz5/17CoQeMwl3/dmpk/9W3v+Cnek4Z3YInrz4b//mHVVj20nb88dIT8KvHN0TO+fyfX8DY9hxsh+Ph19yWzCfOnYDH1obTQq/8wyqMUFrO6lxDFnMF4/Rx7djCwi2dP3rSLPzi0fUA5Mpi94s/d9IIrN25Hx8+8SCs2tSJ/pKDce15TBndgu1d/aHriFn7/KmjQ1bJWxdMwUtbu/Duow/E7c9sxrGzxuOWFe5aByIwfMVZ8/DVpasB6LOB2lvcbZefOQ9f+ctLoW0mi8oPFhsUgU4IHzdnAgDgnQvjc7arhayLzj9iKh7xPut6cNkZB+MLf37BmAUGBEr5X886uKJ7fPiEgyo6jxiaNLUiECuLbTfk5ssdO4XwfMOr7BXN2VT29RVRchzs2hf0zN+wO1wN/IN/PBqf+t3T2K+0kxipuFYOHNuG5Vee5q2uZYXaPay/7nwA8BWBGiyeMroVy688HQBw1W3Pu4pgRA5PXn22f43Lb34Gd67a4s+w/3rFKaH7//jiRZH7CVpylr9NKAJdFW1LNuMfJxRBuQVAhBvJjlkLWWX2xBGRMdYSeab9g388um73BYCLjz8IFx8fL6hzGavi96Oe7yMxOGhqRSAEq1w9Ww4x6xU9eaLXdBeSlyetsqLJZy2/179MPmNFXCutOSuRjx8IhKeu1XIuawH90awhtbVEGvQLsyS7zoQR8T3tRRZTsUrdXWsBeVyI4URTB4v7pCweXf65bptImxT+ft011WUh5aBoqyH7J5dhEdeK+jpu9Sg/a0j8loS7sBJURSIEt5o+moSB+J7LVfaKsZeq1NSvFsQVcxHEUKPJFUEgaOK6fsqIWfvWGEWwv2Abawza8hlt9k8+G7UI1Neq60hGpGfmfYsgEFS5rLtgzRhjryHjZY0MZEZcziIQ1kxcMLTRUDYOMZxoakUg9/7v6Im6evo0awO0+ooguhYv59y/Zoemp484XyeQcxkr1M9fvpcgdmlCK1xZLLd2yGUsjGnLRbJtxOVSWQRVkM0iWGxCuKrSNvWrJ5SNQwwnmloRyIJe14xNpwiEAFAtAsfhKNocYhJrms3aDkc2Y0WqiHMZKxJsrWT9UhErkC0CtwYh6o4Rnq9KYgQDEYNxdQBA+TqCwQDpAWI4MewVwZ2rtmBTR5C101e08fNHXoftcKNFcMtTG7FzX39ktbCVGzp85bBu5/7Qvl89vh7X3PlC2fEId5S6oHlL1orM+Ftz6T8esVykPGPNZ63Y+EKaplfVyNMvN5suV0cwGBgMHSMJoloM66whx+G4/OZnMHVMKx6/6iwAwPfvW4Pv378G40fk/UpfIFjKcee+fnzutufxmbcWoE7q33PDYzhx7gTtvb70fy/FjuXAsW3YXyjh7UdMBeBm8MhppSLbZ/7U0RjTlsPj63ZrC7QuXDwDe6SMpSvPOQRLn9/qv54/bTTachkcOT0okDthzoRQzyGVgXY//NDxM7Fxj+squ+DIaWWPtyw39173fID7DLkMw6fPNOfAL5g2GmceOrmyAVeJSaNacPlZ8xo6BoKoBsNaEfSV3Nm77MYRaZ/7+kvoLdoY1ZrFvr6SP9MXQnZzZzQGALgWxdQxrf41P3XGXPzg/rVlx3LUzLH4vpRvrgaMxYIyf73iFDzy2i48vm631jX09XcfEXr9r2fNw79Kwuic+VOw+r/PDR1z1XmHxY5toIrgq/9wuP/3dy88quzxGYvF5t6PacvhtWvPi73G0stPid1fD576r7PLH0QQQ4Bh7Rrq1WQC+XCOvqLt+86F0hAuIlN6aG/RwdQxrf7rkS1ml4uMOvtVffZyawghmNvy6WMEaRDejTQxAhFXGIhrhAKtBDG4GN6KQBPslff1Fm1/Zi6UhqgB2BJjERwQUgTJhHW5mgC5a6gIlrbWYL1bHfUWzKQICGJw0RBFwBg7lzH2CmNsDWNsSa3uo6sYFvn9HT1F9BUdv7hLrDYm0j5NS0J29BRC+fyFhAFNdXYfsQiyUYugtcYWgV8vV2e5PBhWZCIIIqDuioAxlgHwAwBvAzAfwIWMsfm1uJcu/VPM+Dt7CujzYgQWCyyCDn+/vg6gs6cYmt3v69Mfp6LO7tUYQcg1xIRFUFtFUAm+7hiALCc9QBCDi0ZYBIsBrOGcr+OcFwD8HsA7a3EjnSIQM/6O/UX0FW205TJoy2X8Y00KQEb293f3lSL7dSuNqbN7YYmIa+UaECNoFJR6SRCDi0ZkDR0I4A3p9SYAx9XiRmqM4LXt+7ByQwcA4K4X3bUE2vIZtOYy+Okjr2PHvn48+fruyHVU5FRM0cFUpjWXQZeiINTZvWgh3J7PoLdohxaU8WMEFdQRpIHkMUEQQGMsAp34iTjaGWOXMMZWMMZW7Ny5s6IbqTGCvzzn5ttPGhX0umnNZfyb37lqS6RX/xVnzcOsCe2hPv0jWzL44tvn42Mnzcalp831t08cmcexs8bh8rPm4eDJIzFn4gh8/vzDcPZhU7B49vjQdRdMG41T5k3EwhljAQDtknKZOb4dpx0yCUfPHFfRc9eSL759Po6YPgZvnhZdyIcgCJeLjjsIh0wZifctmtHooSSiERbBJgDyuzMdwBb1IM75jQBuBIBFixZVVGKqWgQdPQWMacth2b+fioVfWQbAVQQ6F5LgouNn4t/POQQ79vVh8bXLAbhunfdLH/D/vOdwfO6257Fg2hjc9LHFAIAPSf3i//mUOZHrjm3P49cfPw5fvMOtRh47IogZtOez/nUGG0fOGIs7P31yo4dBEIOaaWPbcM+/n9boYSSmERbBUwDmMcZmM8byAD4I4M5a3EgV8B09RYxrz4WCva05y1cYok+PnMEzti0f+g1EM34q6QkkEFlMcWsN1Ip6re9LEMTgpu6KgHNeAvBpAHcDWA3gVs75i7W4l6oIOnsKGNueDzV3a8tlfIE4e+II9/eEEf7+YAnI4Bw142cgikDEEuIWpicIgqglDakj4Jz/lXN+COd8Luf82lrdJ2oRFDCuPRfKWpGF+CxPARw0oT32uurCMuqC8WkQWUe6xWpqDQWLCYIAhntlcSEIFnPO0bG/GHHByKmgE70g8oSR8QunmDp5VuJpEVlHjXANEQRBAMNcEYj+QYBbOSxcQzJyiqZwz8S1bAaAsYaVvipBWASjNLUHBEEQ9WBYKwK56dzFP3sS+wt2rH+/JRst7tKRVfd7LpZKKmZFoDpuGcqaQ0FjgmhqhvU0dPq4NswY34aZ49tRLHGcMGcCTn9TuId9ay6Dmz62GKve6MRHTpyFdTu78bGTZiGfYVig5Mr/4p+OxYtb9kbuc9LciXjfMdNxxdnpe9P/6EPH4JanNuLAsW2pzx0onzv3UDic44KF5dcQIAhi+ML4EMghXLRoEV+xYkVVrzlryVIAwB2fOglHekVdRG0R7/n6685v8EgIojlgjK3knC8qd9ywdg0lYSCpnwRBEMOBplcEpuUSCYIgmoWmVwS1buxGEAQx2Gl6KVjrxV8IgiAGO02vCMg1RBBEs9P0iqBczQBBEMRwZ1jXEcSx9PKT8eS6PY0eRlNx08cWo6s32dKeBEHUj6ZVBAumjYkUjBG15bRDJjV6CARBaCC/CEEQRJNDioAgCKLJIUVAEATR5JAiIAiCaHJIERAEQTQ5pAgIgiCaHFIEBEEQTQ4pAoIgiCZnSCxMwxjbCWBDhadPBLCrisMZzNCzDj+a5TkBetZacBDnvGwl55BQBAOBMbYiyQo9wwF61uFHszwnQM/aSMg1RBAE0eSQIiAIgmhymkER3NjoAdQRetbhR7M8J0DP2jCGfYyAIAiCiKcZLAKCIAgihmGtCBhj5zLGXmGMrWGMLWn0eAYKY+znjLEdjLEXpG3jGWPLGGOveb/HedsZY+y73rM/xxg7unEjTwdjbAZj7H7G2GrG2IuMsSu87cPxWVsZY39njK3ynvXL3vbZjLEnvWe9hTGW97a3eK/XePtnNXL8aWGMZRhjzzDG/uK9Hq7PuZ4x9jxj7FnG2Apv26D9/x22ioAxlgHwAwBvAzAfwIWMsfmNHdWA+SWAc5VtSwAs55zPA7Dcew24zz3P+7kEwA11GmM1KAG4knN+GIDjAXzK++yG47P2AziTc34kgIUAzmWMHQ/gfwB823vWDgAf947/OIAOzvnBAL7tHTeUuALAaun1cH1OADiDc75QShMdvP+/nPNh+QPgBAB3S6+vAnBVo8dVheeaBeAF6fUrAKZ6f08F8Ir3948BXKg7bqj9ALgDwDnD/VkBtAN4GsBxcIuNst52/38ZwN0ATvD+znrHsUaPPeHzTYcrAM8E8BcAbDg+pzfm9QAmKtsG7f/vsLUIABwI4A3p9SZv23BjCud8KwB4vyd724fF83sugaMAPIlh+qyeu+RZADsALAOwFkAn57zkHSI/j/+s3v69ACbUd8QV8x0AnwXgeK8nYHg+JwBwAPcwxlYyxi7xtg3a/9/hvGYx02xrphSpIf/8jLGRAG4D8G+c8y7GdI/kHqrZNmSelXNuA1jIGBsL4HYAh+kO834PyWdljL0dwA7O+UrG2Olis+bQIf2cEidxzrcwxiYDWMYYeznm2IY/63C2CDYBmCG9ng5gS4PGUku2M8amAoD3e4e3fUg/P2MsB1cJ/JZz/idv87B8VgHnvBPAA3DjImMZY2KiJj+P/6ze/jEA9tR3pBVxEoALGGPrAfwernvoOxh+zwkA4Jxv8X7vgKvcF2MQ//8OZ0XwFIB5XlZCHsAHAdzZ4DHVgjsBfMT7+yNw/eli+4e9jITjAewVZulgh7lT/58BWM05v17aNRyfdZJnCYAx1gbgbLjB1PsBvNc7TH1W8R68F8B93HMsD2Y451dxzqdzzmfB/S7exzm/CMPsOQGAMTaCMTZK/A3gLQBewGD+/210UKXGAZvzALwK1+f6X40eTxWe52YAWwEU4c4iPg7Xb7ocwGve7/HesQxu1tRaAM8DWNTo8ad4zpPhmsbPAXjW+zlvmD7rEQCe8Z71BQBf9LbPAfB3AGsA/AFAi7e91Xu9xts/p9HPUMEznw7gL8P1Ob1nWuX9vChkz2D+/6XKYoIgiCZnOLuGCIIgiASQIiAIgmhySBEQBEE0OaQICIIgmhxSBARBEE0OKQJiWMMYs70OkOIntgstY+xSxtiHq3Df9YyxiRWc91bG2JcYY+MYY38d6DgIIgnDucUEQQBAL+d8YdKDOec/quVgEnAK3CKrUwE82uCxEE0CKQKiKfFaHdwC4Axv0z9yztcwxr4EoJtz/k3G2OUALoXbFvslzvkHGWPjAfwcbtFQD4BLOOfPMcYmwC34mwS3AIpJ9/oQgMsB5OE2z/skd/sLyeP5ANwOuXMAvBPAFABdjLHjOOcX1OI9IAgBuYaI4U6b4hr6gLSvi3O+GMD34fa9UVkC4CjO+RFwFQIAfBnAM962qwH8ytt+DYBHOOdHwW0ZMBMAGGOHAfgA3CZkCwHYAC5Sb8Q5vwXA0XBbjB8Ot8r4KFICRD0gi4AY7sS5hm6Wfn9bs/85AL9ljP0ZwJ+9bScDeA8AcM7vY4xNYIyNgevKebe3fSljrMM7/iwAxwB4yuue2oag2ZjKPLhtBgCgnXO+L8HzEcSAIUVANDPc8LfgfLgC/gIAX2CMLUB8y2DdNRiAmzjnV8UNxFvOcCKALGPsJQBTvTUK/pVz/nD8YxDEwCDXENHMfED6/bi8gzFmAZjBOb8f7mIqYwGMBPAQPNeO11d/F+e8S9n+NgDjvEstB/Bery+9WLf2IHUg3F3OcCnc+MA34DYqW0hKgKgHZBEQw502b2YtuItzLlJIWxhjT8KdEF2onJcB8BvP7cPgrqvb6QWTf8EYew5usFi0Ff4ygJsZY08DeBDARgDgnL/EGPs83NWqLLidYz8FYINmrEfDDSp/EsD1mv0EUROo+yjRlHhZQ4s457saPRaCaDTkGiIIgmhyyCIgCIJocsgiIAiCaHJIERAEQTQ5pAgIgiCaHFIEBEEQTQ4pAoIgiCaHFAFBEEST8/8BdEE+BpKXv5UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c8cf06710>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = Agent(state_size=37, action_size=4, seed=0)\n",
    "\n",
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]            # get the current state\n",
    "        score = 0\n",
    "        for t in range(max_t):            \n",
    "            action = agent.act(state, eps).astype(int)       # select an action\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done) \n",
    "            score += reward                                # update the score\n",
    "            state = next_state                             # roll over the state to next time step\n",
    "            if done:                                       # exit loop if episode finished\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "\n",
    "We can make some improvements to solve the environment to fewer episodes\n",
    "\n",
    "- Different Batch_Size may result to faster training\n",
    "- GAMMA factor can be set closer to 1 so that we can make immediate results more effective for our agent when bananas are close enough one to another\n",
    "- TAU parameter will tweak target network's weight to match those of the local network. Closer to 1 will result in full sync and closer to 0 at NO sync.\n",
    "- UPDATE_EVERY is a factor that we can change and result to improvements. Here we selected 4 and if we set it to larger numbers will result to improvement of generalization.\n",
    "\n",
    "We can also use Reinforcement Learning refinements.\n",
    "\n",
    "- Double DQN - Deal with overestimation of action values.\n",
    "- Prioritized Experience Replay - To make important experiences more relevant.\n",
    "- Dueling DQN - Improve performance by dividing a neural network in two streams. One for state values and other for advantage values.\n",
    "- Rainbow DQN which incorporates all six of below algorithms\n",
    " 1) Double DQN (DDQN)\n",
    " 2) Prioritized experience replay\n",
    " 3) Dueling DQN\n",
    " 4) Learning from multi-step bootstrap targets\n",
    " 5) Distributional DQN\n",
    " 6) Noisy DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
